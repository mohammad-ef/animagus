# Distributed Job Execution Engine "SparkJobExecutor vX.XX (SJE)"

### Overview & Design Principles

The `SJE` provides an asynchronous framework to distribute long-run time intensive tasks/ jobs amongst several execution worker machines/nodes within an infrastructure. The core architecture consists of an Executor, Task Manager and Worker node. Each job/task is represented within this ecosystem via JSON data structures, allowing easy portability amongst worker node instances and enabling easy scaling and management of job resources within an overall infrastructure deployment

The engine uses zero configuration deployments, leveraging the native infrastructure and its existing security constructs. Each Executor and Task Manger can run anywhere with appropriate network access to the cluster's worker pool nodes, minimizing operational burdens.  

SJE is designed primarily towards data processing tasks and is highly modular and flexible with a plug in interface which provides easy extension for specific task-dependent operations (e.g., logging, persistence, monitoring).  

Furthermore it supports various task dependency configurations, ensuring that tasks run sequentially or parallel, allowing developers the control required to orchestrate complex data workflows, ensuring reliable and scalable processing pipelines, reducing bottlenecks, minimizing costs by distributing workloads.

We leverage a publish-subscription architecture for communication among components allowing event- driven decoupling, simplifying system management and scalability. This enables easy extension, addition to new tasks, scaling, and integration of additional systems and features as our infrastructure evolves.
 
Spark Job Executor allows the decoupling of computationally expensive, long-running jobs from primary request processing threads, which ensures that main web/api servers do *not stall.*

 

 
 
 -------------------------------------------------------  
 **Project Title:** SparkJobExecutor vX.XX( SJE) - A Distributed Job Execution System  
 
 ### **1. Description**
 
 The SparkJob Executor vX.XX (hereinafter "SJE") facilitates asynchronous, distributed execution of time-consuming processing jobs/tasks, leveraging a scalable worker network and JSON data structure, designed for data processing tasks where long runtimes might affect core operational servers. 		 		 		

 SJE's modularity is a key advantage; plug-ins allow for task dependent custom behaviors like data logging and monitoring with a plug in based architecture to ensure flexibility. The plug in API ensures that custom behaviors like logging, metrics gathering, task retry/ failure, can readily be applied, making deployment adaptable.  					

 It supports complex workflow orchestrations utilizing dependency resolution for sequential asynchronouse parallel operations. This is accomplished with a publish/subscribe system allowing for loosely coupled task execution, enhancing resilience to component failures.

 Zero config deployments minimize management overhead, leveraging native network/ security protocols, reducing the time to onboard new tasks to an already established worker pool and simplifying the operational burden of a distributed execution engine deployment and management. 

  This architecture minimizes overhead to web servers as long processing activities are delegated to an independent worker pool which enables them to focus primary tasks, reducing the latency of main operational services to clients. This enables high availability and performance under load with a distributed architecture designed for scalability and fault tolerance.  				 				

 -------------------------------------------------------
  **Project Title:** Installation and Configuration Guide

 ###  **Instructions:**

 This section provides installation steps and instructions to configure SJE within an infrastructure. Before initiating installation, review dependencies section below, to assure required environment components exist.

 Firstly create your virtual environments to isolate the project. We recommend `Virtual Env` tool, `conda create -name sparkjob -y python=3.9` This is a common approach but `poetry` or another dependency managmenet tool is acceptable. 

 Activate environment `conda activate sparkjob`

 Install core requirements using package management tool `Pip`, or other preferred approach such `Conda Install`

 The next critical component of your SJE is your message bus/ queue. The project requires access a reliable publish/ subscribe system. This example, Rabbit MQ has shown great performance, though other implementations are acceptable as an alternate solution (Redis Pub/sub, ZeroMQ ).

 Download RabbitMQ and install on an available instance `apt update && apt install rabbitmq-server`. Configure RabbitMQ with the appropriate networking access rules allowing worker nodes access.

 Ensure proper network configuration is in effect, permitting Executor instances to send, receive, and queue messages with the broker service. 			 

 Verify required system libraries are available on each host, including Python interpreter, `json` libraries, `logging `and `requests` modules. The specific dependencies can easily be installed using `PIP requirements.txt install`.	

 Lastly configure environment variable pointing the location of `config. yaml`, the core of configuration settings that drive the behavior of components. The location will typically depend on environment deployment.	  
 
 Configure your RabbitMQ service. Ensure the necessary queues exist, and appropriate exchange bindings for communication. `declare queue` commands are often required within the queue management UI/CLI. 	  			

 Configure user access control and network access restrictions for all nodes. Secure the Rabbit MQ instances and other components to prevent malicious access attempts and safeguard data within the infrastructure.	

  After installation, verify connectivity and communication. Ensure the components interact appropriately and that task execution flows as intended via the message broker instance within your environment and deployment setup.

 Test your environment configuration, to confirm all dependencies exist, the correct versions of the libraries and dependencies installed within the environment and Rabbit MQ instances are operational with connectivity enabled, before deploying tasks into your operational pipeline environment.

 The final step to setup is defining the required task configuration within `config.yaml`, including Rabbit MQ credentials and other task specific configurations.

 -------------------------------------------------------
 		 
 ### Usage Instructions

 	 To run a task within Spark Job Executor first, configure and deploy your Executor instance within your environment and deployment setup.	 

 Once Executor service deployed to a running host within the environment.  You can now invoke task via an POST request with `JSON body.`
 To invoke your task, create JSON formatted structure representing your job and send POST request with that structure:  `curl --data '{"task_id":"task_1", "function": "calculate_data", "params":{"input_data": [...], ...}}' http://<executor-host>: 	 8080/submit 		`.

 Monitor task progress through Executor logs and message queues, observing task states and completion events for a better workflow overview.

 For advanced configurations and dependencies define the `task_dependencies` within your `configuration file`, ensuring that tasks run sequentially as a chain of asynchronous operations, allowing workflow management. 		 				

 The engine supports event- driven processing, with events triggered on task success and failure enabling real- time notifications of task state updates, allowing integration with monitoring services.	  
 
 Error handling is a key element of task processing. When exceptions are caught, they will trigger error notifications, alerting the operators to issues requiring resolution within the operational environment, enabling efficient problem resolution 				

 The engine offers REST API, including `/status <TASK_ID` endpoint for monitoring, `/cancel 	 <TASK_ID>` and other management endpoints, which are useful during debugging and troubleshooting. 						

 Task dependencies can also be handled within code, enabling the task to perform additional operations based off of previous executions.

 -------------------------------------------------------
 

 ### Configuration

 SJE is configured primarily via `config.yaml` file, containing task settings that drive its behavior within the overall operational environment. 

 `RabbitMQ` settings include hostname, port, username, and password to establish connectivity, authentication credentials, to ensure communication with broker instance 	

 `Executor` configuration parameters like `worker_nodes` list and `max_concurrency`, define which nodes can execute jobs in a worker node list, and number of workers running concurrently on the host.	

 Task- Specific parameters, including `retry policy`, timeout, `logging levels` can be customized based upon workload characteristics and requirements of operational infrastructure.	  			

 `Plugins configurations`, allow enabling or disabling features, customizing behavior of modules and plugins, to enhance functionality as required and tailored within the infrastructure.	 		

 Security configurations include `authentication methods`, `authorization scopes`, and `SSL settings`, which are important to secure the execution engine with the proper controls.		 

 Environment variables can override YAML configuration settings, allowing externalized configuration for deployment in dynamic, infrastructure environments.	 		

 Logging configuration, define `logging levels`, `output destinations` and formatting to enhance debugging and monitoring efforts. 						 

 The `task_dependency configuration` enables chaining of tasks for workflows. Define a sequence of tasks and order, allowing complex data flow pipelines. 

 `Monitoring integrations `, include metrics collection configurations and alert rules to facilitate proactive issue detection, alerting operators, enabling efficient problem resolution.	

 Finally, review your overall configuration file thoroughly and perform testing to identify unexpected interactions between different components within operational environment.		  
 
 To adjust logging levels modify the `log_level configuration` and apply to relevant logging components in the configuration file.	

 Ensure the RabbitMQ connection details are correct and that user/ password are valid for authentication.	

 Verify `worker_ node list` accurately reflects all available execution nodes.  Incorrect configurations will cause execution failures.				

 ------------------------------------------------ -------
 ### Project Structure

 The SJE project follows a modular structure to ensure flexibility and extensibility. This section outlines core elements of project architecture.

 The `src 			 /` directory holds all the project source code including `Executor`, `Task Manager`, and `Worker Node implementations` as core execution components.

 The `plugins `/ directory contain all plugin source code, enabling custom behaviors and extensibility. 		

 `tests /`  is where automated unit integration and testing suites for the engine are maintained and run during development and testing efforts.

 The `config `/ folder holds all supporting `yaml` configurations used by `SJE.` and other environment specific configuration.  		

  `docs /` includes supporting information on design decisions or any supplemental materials that describe functionality for external usage/ reference materials 		

   `dockerfiles`/ includes Docker files required for packaging `executor, ` task manager and individual execution worker node implementations into a standard deployable artifact format 				

    `README.md `provides overall instructions regarding this software product.		

 `LICENSE`/ file contains all details and stipulations associated with software project open license terms for public usage, and usage requirements 						 			

	 	 The project leverages standard Python module design to improve code clarity organization to facilitate easy development efforts within engineering groups and teams.

	 The test suites contain both individual component integration, to improve reliability during software upgrades within a development lifecycle

 Project is built in modules to encourage independent testing, modular deployments in production infrastructure for scalability purposes	

 ---------------------------------------------------------
 ### Contributing

 To help with project enhancement contributions via GitHub pull requests are welcome. Before making submissions read `code of conduct`. 

 Report issues, bugs and enhancements to GitHub Issue tracker to track all active concerns or potential new developments 			

 Fork repo `GitHub` project for creating local working branch and implement your code contributions, following code guidelines as outlined, within `code.md.` file,

  Follow established style guides for consistent style within codebase; adhere with Python code standard PEP 8 guidelines during coding efforts.					

  Create comprehensive unit, integration, functional test suites with existing tests and new testing efforts to demonstrate stability during upgrades in environments 	

 Provide descriptive change description for commits and code pull request. Ensure commit and PR are self contained with relevant tests/documentation, and descriptions of code contributions				

 All changes should pass CI /CD automated testing before code merging. Review automated test output before submission; and fix issues to prevent deployment regressions						

 The project uses `gitFlow`, following version release strategies with a stable branch to enable stable environments in deployment, with a dev/main stream of ongoing improvements	
 

 The SJE development welcomes any feedback on usability features or performance, enabling community collaboration within a open environment

 All external contributions subject review by SJE project maintainers to verify alignment. Ensure changes align with long term development roadmap of SJE		
 

 Contributions will be released into project with appropriate credits, in acknowledgement for all efforts improves product quality of overall engineering project		
 ------------------------------------------------------------
 ### License

 This project is licensed under the MIT License, a standard permit where usage can include, modify, redistribute software freely, within reasonable limitations 					

 You should ensure attribution towards SJE, including the appropriate licensing details when using software product, adhering terms related copyright and License details				

 Any liability arising, from usage will not affect original copyright. Use these components to improve products while complying all stipulations within licensing document			 					 			

 You acknowledge that use the product implies adherence the entire terms. Please review license details for clarification on any usage-specific conditions	 		
 ---------------------------------------
 ### Acknowledgments

  SJE owes great credit RabbitMQ developers enabling the reliable and fast event based messaging required for core infrastructure	

 Thanks also to contributors to standard libraries like, Python standard `request, `json libraries used extensively in task handling.						 				

 The community for Apache `logging project` and `PyYAML project`, are key to logging configurations management for overall operational environment tooling.		

 Thanks also go out for all early users feedback which guided improvements of initial version; providing essential context to drive enhancements, improve features, resolve errors		 

  Special credit towards Python core development which provides excellent tools to simplify engineering effort to enhance developer workflow 
 The community provides open libraries which enable faster deployment within development and support for ongoing development sprints

 SJE leverages several standard libraries which provide critical tools which greatly improved the speed with the overall product development efforts
  

 Acknowledge contributions from all engineers, and stakeholders and external collaborators that enabled SJE product and overall operational framework deployment		 		 
 --------------------------------------------------------------
 ### System Architecture

  SJE consists three core architectural units : the Executor component responsible receiving incoming tasks and delegating work execution and the RabbitMQ component providing event messaging infrastructure

 Executor and Task managers, each are standalone microservice that communicates using publish/ subscribe system; each component handles independent functionality and scales as needed to ensure maintain scalability
	

   SJE architecture supports zero configuration, deployed across multiple worker nodes and managed within RabbitMQ. Worker instances register within the cluster with available resource capabilities, to provide flexibility in task distribution			

 RabbitMQ facilitates task scheduling, dependency tracking, error monitoring as an external independent service enabling enhanced decoupling between various components of infrastructure

 The system adopts a event based pattern allowing loose assembly components. Components publish events as task status updates. Subscriber modules process and respond in accordance.						 				 
 SJE employs REST API exposing endpoints enabling remote task interaction monitoring. Provides flexibility management capabilities

 Task workflows leverage publish-subscribe paradigm; events broadcast for specific task state transitions triggering appropriate handlers.  

 This decoupled nature enhances flexibility. Modules can adapt to new task requirements, ensuring scalability of entire system with modular enhancements			 

 The framework embraces microservice architectural patterns for independent development scalability for modern cloud infrastructures, supporting agile work methodologies				 		
 --------------------------------------------
 ### API Reference

 `SJE API exposes endpoints facilitating Task interaction.` This includes `/submit` `Endpoint `receives incoming jobs` and other API for task control

 `The `POST/submit`:  Submits tasks for processing via an API with task configurations.` 					 	  The body requires json with Task ID `name of`  `Run method` along parameter values
 `Return value`: Success code or failure codes

  `/status/:task_id` returns current `execution statuses for task. ` Returns Task id status JSON

  `/cancel/:task_id `allows cancelation running execution jobs via a task id identifier, providing ability control task processing	 
 		

 All interactions must authenticate through a provided access key or OAuth, preventing Unauthorized configurations within an operating framework			 		

 Error code: HTTP `code` will indicate the reason the call returned, 201 `is` for created,  500 for an issue, etc 	
  Additional parameters defined through `config.yaml` allow configuring specific endpoints to meet operational demands and specific use cases		
	

   Request and response body format JSON standard; `JSON structure must follow` SJE `schema requirements.`			

 `Additional details and specifications documented separately for API` usage.						 
 ------------------------------------------
 ### Testing

  Comprehensive Test suites enable quality and maintain stability. Tests are automated within a `Pytest test `framework.					

 Execute unit, and integrated, testing using automated `command pytest test ./`, providing quick and consistent testing for all project functions methods 			

 `Setup environment by configuring test databases mock` `external resources`. Ensure dependencies required met within `pytest config settings file.`	
  Testing covers edge conditions, failures error, recovery procedures; `Ensure that code covers various operational edge case conditions`.
   Testing suite covers unit test `functions`, module tests with integrated interactions, performance metrics, load-time testing	

 Integration Tests: Verify interaction of multiple module classes components and dependencies correctly within a cohesive architecture 
 Load Testing, measures performance and scalability capabilities; simulate conditions where SJE is being utilized with many simultaneous users/processes			 
 Implement `Continuous Integrations (CI)`, automate, execution testing whenever there is `push`, and commits on GitHub; this allows early feedback of code quality				 
	 The goal automated tests is prevent regression. Tests prevent new bugs from being released; ensure overall code integrity and maintainability 

	 Testing provides confidence when upgrading/releasing; automated execution and results verification. 			
--------------------------------------------
 ### Troubleshooting

   Connectivity issue, RabbitMQ connection issues or task execution failures, can often occur in initial deployments or running infrastructure.	 

 `Connection timeout errors, indicate problems with the broker Rabbit MQ.`, review the host names user access and credentials are correct	

 Dependency errors arise during the import modules. Doublecheck that version requirements met with correct installation, ensure dependencies installed in environment
  Incorrect permissions can trigger execute issues and error handling during deployment.	
 Check configuration files, and environment variable settings carefully for typographical error causing unexpected configurations 					

 Logging is essential debugging: Enable verbose levels logging for debugging to get granular task- related events. 

 If `Executor does`not process any new submissions. `Restart services. Review configuration, verify Rabbit error log and connectivity with worker instance	 	 	 	
 When a specific error message `cannot resolve` check the associated application, `Review application specific configuration files.	`			

   Review error log and `trace logs to` identify specific issues or potential root causes within application environment			 					 

 For `unpredictable results or incorrect results`. Double-check input configurations database connection or network configuration 				 				
 -------------------------------------------
 ### Performance and Optimization
   
 The engine offers multiple methods performance tuning, including caching task parameters optimizing network communication between components and using concurrent execution	 

 Utilize message queuing systems Rabbit MQ efficiently: Configure Rabbit queues, exchange patterns effectively and limit consumer concurrency, improving efficiency 			

 Employ asynchronous tasks and worker thread- pooling: Delegate heavy computational activities asynchronous pool worker-thread execution 		

 Monitor application metrics like latency and resource consumption identify and resolve the issues: Track response rates resource allocations.			

 Use data-structures, algorithm choices carefully for optimal execution times when processing tasks and delivering final product
 
 Cache results and data when relevant reducing the processing overhead; improve application response speed by using data from local resources instead
				 				
 Profiling application with dedicated profilers tools can expose areas performance degradation enabling focused improvement effort

 Consider hardware improvements and scaling for high demand; allocate additional processing cores storage capacity to optimize resource performance.						
-------------------------------------------
 ### Security Considerations

 The Engine prioritizes protecting system, tasks by ensuring data is protected. Use strong Authentication authorization, to secure API, control user interactions with components				 		

 Secure communication through encryption protocols tools (TLS HTTPS ). Protect against unauthorized access, and maintain confidentiality
				 
 Data validations input data sanitize, prevent injections SQL and command executions from untrusted inputs	
				 				
 Securely management and rotation, API access and credential to ensure access is only given appropriate and legitimate access requests		 		

 Employ regular penetration testing audits to uncover vulnerability within infrastructure, ensure compliance security standards	

 Regularly review system configurations monitor access and security events and log activities	 	
  Stay current patches vulnerability releases; maintain up to-date environment, protect vulnerabilities
 Implement least access permissions: work on minimizing unnecessary privileges for all roles, to decrease surface security exploits

--------------------------------------------
### Roadmap

	The following outlines SJE direction, future features:  Improved performance through better RabbitMq configuration
	
 Improved support for more Rabbit MQ message protocols: Enable better compatibility for other RabbitMq configurations
			 
 Support task dependency graphs and automated execution workflow. Enable developers build and automate workflow orchestration. 	 		
 	  Implement enhanced monitoring capabilities; provide an API integration with other external tools	 	
 
  Integrate improved health monitoring: provide faster feedback to improve stability within an overall deployment

 Improve documentation through better API specifications examples: provide comprehensive guides enhance usability for developers	
	 Implement more plugins support; allow community expand features and customize functionalities	 			 	
 Support multi-region, global execution and deployment with automated load balance, enabling high performance for globally located applications

--------------------------------------------------
### FAQ (Frequently Asked Questions)

 What are primary prerequisites running a project. `You` `Require` Python version > 3, rabbit-mq with access permissions to create user, queue exchanges for SJE to work effectively, with basic RabbitMq configurations setup.

 `I have connectivity problems with SJE` Check `host-naming, access authentication credentials are all setup`. Verify RabbitMQ server accessible with correct permissions and configurations
			
 What type Rabbit messaging systems SJE compatible .	Currently `we support ` standard protocols within messaging ecosystem and we aim extend our features, in coming version	

`Can i scale executors?	 `SJE architecture is scalable; can deploy executors multiple instances for parallel job processes with increased reliability			
-----------------------------

 ### Citation
 For any citations regarding SJE research/ publications.

  `@misc{SJE,
   author = {Project Contributor, Name and/ Affiliation, },
   title = {SparkJobExecutor A distributed asynchronous system },
   year = {2024},
   note = {GitHub Project}
   }`

 Ensure accurate and full citations within publications to recognize effort made to produce open sourced software project for academic usage		 			 		
------------------------

### Contact

 For assistance related project, feature enhancement.
 `GitHub` Issue Tracking enable community discussions.	Contact project developers through community forums.

 Provide details regarding environment when contacting for technical issue.

 We also maintain an online documentation site, containing details related setup configurations usage examples and provide additional troubleshooting guides	.					

 We also accept contribution and appreciate community input and collaboration on project enhancements		
