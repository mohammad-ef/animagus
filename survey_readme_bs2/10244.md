# StellarMapper - An Autonomous Celestial Mapping Platform 

## Description

Welcome to Stellar- Mapper - StellarMapper' is a distributed autonomous platform built for comprehensive star charting using an open- source approach. This system allows geographically disparate computing units to pool their observation resources, generating a far- more precise galactic cartographic product compared with traditional approaches. It is primarily designed with citizen sciences as its user group. The system is built as micro-servers that connect together to build one galactic map.

At their core we utilize the Bayesian approach for mapping, taking a probabilistic view into celestial bodies to build our maps from observations. The core architecture leverages message queues (Kafka), allowing asynchronous operation to increase reliability, throughput and fault tolerance to failures within individual processing machines within each distributed node in a system network of these micro-servers. This ensures a high resilience against individual system outages during operation.

Data processing occurs using parallel algorithms written mostly with the Go language for optimal performance, allowing a massive data throughput and minimizing resource demands.  The output is generated and stored on the distributed nodes in Geo-Spatial format which facilitates seamless importability into a host of GIS (and other) platforms for downstream usage.

Our main goals include building an extremely detailed galactic map for citizen scientists to use and providing an extensible API and data format for further development by interested parties; we welcome collaboration to extend these core goals. Finally, this framework enables real time updates for the galactic maps and is intended toward continuous improvement and discovery. We are using open source libraries and frameworks wherever available in this system.

Finally we provide a user friendly command- line interface and a REST endpoint API which facilitates data upload and query, making the process of data collection from users easier to use and extendable by other applications. This design makes data accessible and useful to a range of applications including research institutions.

## Installation Instructions

This is the first step toward getting our platform online - you must be a Go user (version >=17 required to build the platform). We recommend building on Linux as most tooling has been designed toward that environment (mac is supported too, although may require manual patching in dependencies in specific configurations). Building for Windows is possible through using WSL2 or other emulation software to build for cross- platform deployment, although it isn't a natively tested setup path.

You will require a Go compiler installed as well and a package management system for downloading required libraries. This includes git for cloning our repository to get your copy for installation of Stellarmapper.  You can find installation details for Go online depending upon your environment - https:// go.dev/doc/install (for instance.) Ensure it appears properly within a command- prompt (ie. go version ).

Next is obtaining our repository from git - you will need git installed too. This should be readily installable from most operating sytems (usually by typing apt/ dnf/yum/ brew commands). The command to retrieve the codebase to get started is `gitclone <git url of this codebase>` to the desired local location on any host computer you are using. 

Then we will install all the dependencies of our project by simply running `go mod tidy`. If for whatever reason you get error relating dependency, it might suggest some libraries were not found or some other configuration errors on the machine you' re operating - in such cases, please consult documentation for your OS regarding package installation to fix such errors.

For Kafka, we require a working instance to operate and we expect version >= v3 - https:// kafka. apachie. org/download to download and build from source - please review their instructions on their documentation page on how they should get built.  The system will use default configurations if not otherwise overridden in `config. yaml ` (described in configuration later).

You also might optionally choose a postgresql database for storing the mapping metadata as a backend, if desired; we recommend version 13 or greater (but it's likely to perform correctly across more newer version releases also). You can find installation details for postgers online - it will allow you to easily query for map metadata from the StellarMapper platform as you scale.  The default config will use a file-based database for simpler deployments.  

After all of them are installed and configured (including the database or message queue, if desired, or otherwise the default settings work), run `make build` on the root folder for the codebase to build our executable binaries for deployment. You will find the resulting executables in `./build folder`.  

Finally you may optionally deploy the resulting build folder binaries to Docker and run in Docker container. Docker and Docker Composer can provide an easier means for deployment on cloud or on a local server to run the project.  See Docker instructions and documentation within each directory folder inside Stellarmapper. The Dockerfile should have all necessary build instructions to build StellarMapper from source for container usage.

## Installation Notes

Before attempting to execute any of this install procedure you should ensure you' re using a clean system with a working internet connection - Stellar Mapper is a large project, so downloading all packages will require bandwidth availability from the network interface of your machine for downloading all dependencies of the packages from various external websites for building from source.

The Go environment may also be a cause in some cases for build or installation related error. Please consider to set your `GOPATH` environment to be set before building any projects that use it (this includes StellarMapper as it leverages some external tools to do the building process)

If your platform has security policies enabled - make sure the necessary packages needed for our installation (including Kafka, PostGres (if applicable to install)) have been whitelisted.  These may be required for building from sources which is required in this process

For Docker users make sure there are no pre-existing container images from our project. This might create errors while creating images and running the containers as a result. Remove existing image before building a new one, if needed. 

## Installation - Additional Notes

The build folder should contain the core executable for running StellarMapper.  You may also find other utility binaries used for testing. If not, please re-review previous instructions for building to fix any issues in build process.  

You should ensure the executable in the `build directory` can access external resources (e .g internet connection and Kafka) before deploying this to any environment for actual deployment and operation, so you must also check all firewall policies.

## Installation - MacOS Considerations

On Macs please make a note that you may experience problems downloading certain build dependencies that require some additional tooling to be built - in particular you must have Xcode and its command line tool chain installed for building packages correctly on MacOS. You can find instructions for installation online for Xcode.

 ## Usage Instructions
To initiate your first StellarMapper session, please use the command- line application, accessible with `./build/main` in your terminal, where `build folder `is assumed to be the build directory created when installing the Stellarmapper code from our github repository (as instructed in above installation step). 

Once launched the program starts with a command to upload the first observation data from users, so you can begin to populate a map by simply providing data in `geojson format`. For instance if one user observed and recorded an object at (RA: 6 hours, Dec:-30 degrees), then this information would have been saved locally into `geojson format` with associated timestamp and metadata to allow us to build our data structures correctly, so a simple file upload to a server with `data. geojso format `.

To query for the map data we support a rest endpoint `/maps`. If you provide specific search terms it will query the available galactic data. If nothing specified it just returns the overall galactic maps for a specific date range (as recorded within metadata from users) to allow visualization of galactic map evolution over time and location to allow further analysis of the map as it evolves.

The command- line interface accepts arguments, allowing for various options such as uploading local data sets and configuring connection to different Kafka clusters or databases (if configured). To see a full list use `./build/main - help`. We encourage experimentation with command-line tools as it is an excellent approach with building your understanding of what our software does

## Usage Instructions Advanced

To run in parallel you can use the `--num Workers` which enables you to define how may parallel worker processes the StellarMapper platform will utilize to do parallel operations and improve data processing speed - this will scale the performance of this mapping application as more resources are given to processing tasks.  The `--kafka Brokers` allows to point to an alternate Kafka brokers.  The `--postgress URI` can specify an external postgresql database for long-term data metadata to save.

You can configure how to filter and aggregate map data by setting the `--aggregation Method`. For example, if you use `b average` for averaging the coordinates of observed points, it will build a map of galactic positions by simply averaging the locations of observations for each region (defined by a spatial partition) of the sky and then building map data from the average.  

The API can be extended using our open design for additional functionality. The system will allow a user or developer to extend the functionality to create new map projections and coordinate transforms by creating plugin components and uploading to an API.  The system supports a pluggable design to add more features and map projections.

 ## Usage Notes
When querying our APIs we require you to send the `Content- Type header = applicatoin/ json`, and our APIs return responses using same data formats - so ensure you' re setting these appropriately.  

The API will also enforce request limits to protect the servers. Please check our documentation or send support request for more info. Please use the REST APIs responsibly and avoid hammering the servers with requests and follow best practices for rate limits and request size restrictions, when using. If you are experiencing problems using the REST endpoint API you should review the documentation.

## Configuration

The project relies upon the YAML file named `configs/config. yaml `to store configuration parameters that influence operation of this software project. The `configs folder `is the main repository for the YAML file for all configuration parameters to run this software project. If you' ll be changing any settings of the StellarMapper project, ensure these are configured within ` config. yaml `.
This is the first step to configuring our software to run and deploy in a custom envionr ment

We also expose various config settings through environment variables that take pre-cedence. If you set `KAF KA BROKERS`, the system will utilize environment variables instead of yaml configuration files and will override the configuration specified within `configs/config. yalm `. 

Within this `yaml config file ` you can configure several settings including data aggregation settings to build our maps with our system to control how to handle and display data to build our maps from our citizen scientists to allow us to build high-accuracy maps from distributed resources. This enables fine tuning for various environments that might exist.  

You can configure data source locations, database settings, Kafka brokers, authentication keys, and API endpoints. Each setting comes with descriptions for what each one is used for and potential value ranges in our yaml file configuration - ensure that you check the comments on the ` yaml files `.

## Configuration - Environment Variables

The system accepts various environment variable settings for customizing the behavior of the application and overriding settings specified in `configs/config. YAML file ` - this approach is more appropriate to production environment as they are typically deployed in cloud and can be configured via the platform that hosts these. 

Some notable settings that support are `K AFKA BORKERS` to allow to define custom location for kafka instance to connect and `POSTGRES U RI to specify a postgres database for the backend data store. There are additional settings for configuring API endpoints, authentication keys, logging levels, and more within our documentation. 

## Configuration - Advanced

For security purposes you can configure secret management using environment variables - this allows us to not store sensitive credentials directly into the configuration files that we can store into source control - please review how this approach should be setup for the project. 

To optimize system performance you can configure caching strategies to allow us to avoid re processing the already- cached results and improve overall response time - the system should provide better response performance and reduce resource usage overall

You should consult our API documentation for a complete list and description on each parameter setting that we allow to tune our StellarMapper.  The `docs folder `/contains a document describing available API settings to customize our platform as a citizen scientist.

## Proej ct Structure
The project structure reflects an organized micro-services design for scalability and modularity. 

 `/ src/` directory: Houses the primary codebase with all our core algorithms written mostly with our GO code for efficient data processing for our galactic mappings project. 

`/ build/`: Contains the executables for production deployment for running StellarMapper on various operating platforms (such as Mac, Linux or on docker containers.

`/ configs/`: Directory storing project- wide YAML configurations files which control all settings. The main `configs.yaml` is where to change all parameters and configuration options

`/ test/`: All the unit test suites that test core algorithm logic - to guarantee our platform is reliable as possible in real time operations of galaxy mapping project. 

`/ data/:` Directory contains various dataset formats such as `GeoJSON, and csv files`. This contains our training datasets and data formats for building our data mappings in various data sources from around the world from user input

 `/ doc/`: Documentation including API documentation. We expect that you will be exploring this area for more detail to utilize our API and for configuration settings for deployment.
 The system should allow to configure many things and the documentation contains information regarding that

## Contributing

Contributions to StellarMapper are encouraged to expand upon functionality to support even broader citizen involvement for this mapping program, or fix reported errors that we haven `t identified - and all are greatly welcomed!  We have a collaborative community that thrives with feedback and new insights to enhance galactic exploration.

The easiest ways we accept is via opening Github issue for feature suggestions, error bug identification - for which we'll prioritize accordingly, depending on the level of impact or severity for citizen users in their galactic mapping journey .

You are free to implement any improvements that are deemed beneficial - we're open- to all forms of contributions as the citizen community continues and scales - so don`t hestate, reach out when necessary and share. We'd welcome the help and guidance to enhance and improve StellarMapper

For submitting Pull Requests ensure your commits contain tests and that you follow established lint style - for example Go lint rules, as any deviations might require further modifications or changes before being incorporated into the main codebase,

## License

StellarMapper is licensed under the MIT License, an extremely popular and flexible choice - it permits freely utilize our software for a range of usages - both commercial purposes as personal projects for non- comercial purposes as long the source remains visible as well, in compliance and in adherence with all our rules and terms
## License Notes
StellarMapper is freely and easily distributable and deployable to various machines or locations with few to restrictions - please review this carefully if considering any usage and to fully align the usage in synchronizing terms. 

## Acknowledgments

The StellarMapper development has been greatly enhanced through leveraging numerous Open-Source projects that contribute greatly towards a faster deployment cycle - namely kafka to process data inputs asynchronously in our data pipeline architecture, Go programming languages with all it rich features to process high throughput workloads to allow fast processing in a scalable and robust deployment, PostGres databases that we rely for persistent database to ensure our map and user configurations remain secure

Additionally there were a lot of resources on internet which we consulted, from which our platform derives some core ideas and principles, for a distributed approach to mapping that enables scalability.  Many libraries that we have used from community help with development as they allow a simpler development flow to create high end mapping applications with a citizen scientist focus.
 We extend deep and endless thank you towards all those community resources. We have also received invaluable support for various open scientific organizations in providing training resources, datasets and guidance throughout all this process! 

## System Architecture

StellarMapper leverages a micro- services based architectural to ensure high throughput data mapping, resilience with individual components - for example one individual server goes down but doesn 't cause system wide disruptions for citizen galaxy observation efforts! The central hub in operation revolves around using message- queuing to allow decoupled communication between services

Each of the micro services are individually designed using our `GO- Programming language `. We utilize a message exchange to facilitate interactions. Kafka serves the critical messaging service allowing decoupled inter services processing to occur, ensuring that the application remains functional if one of services becomes unstable in any situation - simultaneous operations continue to operate seamlessly without impact
  The overall system uses distributed processing paradigm and is deployed to the various edge computing sites around the world and uses open source frameworks wherever it exists in building our applications
   Finally the map and metadata information gets aggregated using ` PostGreSQL Database to persist long terms data persistence `

## API Reference

StellarMapper is deployed to the open and exposed via an `REST Endpoint APIs to be utilized in other systems `. 

We expose API endpoints like ` `/mapss`/ which can retrieve a current galaxy mapping -`/upload_observation/`: where you submit a `GeoJSON point data observation`.

`/status/:` that reports health state information.

For a specific detail, each request and responses, parameters required for usage and format requirements - please check the API documents at our repository to get complete understanding about the details and specifics to properly interact with this service,
We expect API usage with standard http requests to ensure compatibility and interoperability
## Testing

Running tests in our platform can verify core functional integrity - it will also help you discover and assure that new feature changes do not affect core functions of our platform and our system's overall operational stability, and correctness, 

Running Unit Tests: Execute our `GO testing tools and libraries ` within ` `/ test`/ using the following commands:   go test. - coverprofile.out to create test profiles to measure and identify the test code to cover more test cases. The coverage reports help to assess if all of codebase areas covered with test

Running Integrated Testing - run the following to perform integration of our testing framework with kafka to check messaging interactions are proper and correct: ` go test - integrate `. The `go Testing Library` automatically executes and manages integration of data sources

The integration tests verify all external interactions - to check the correctness with external sources to ensure our mapping data remains stable over deployments in all situations! We recommend that new features or any changes include associated testing cases to guarantee quality
## Troubleshooting

Common problems include connectivity and data ingestion related issues and are prevalent to citizen-scientist usage in our distributed environment. Ensure connectivity exists when uploading new observation. The data formats need be correctly configured with the geojson scheme to be processed

Ensure kafka instance exists as expected with correct credentials, especially with authentication configured to prevent issues from access issues or authorization failures - to guarantee seamless data flows.
If the application does `n respond as expect ` or fails on initial start you check configuration YAML file, ensure settings are configured appropriately - it's easy and simple to check

The server logs contains detailed debugging info if an issues emergence during operation - review this for additional details.  Please send support with a clear error message description - it's critical information and it enables the platform to be quickly assessed for root causes for any failures that occur during mapping
## Performance and Optimization

For maximum scalability - it recommended using `horizontal scaling and container orchestration to increase resource availability and processing capabilities `. Using `Load Balance to route user connections ` is crucial - it can improve system availability during load surges from user activities to allow our mapping platform continue working effectively under increased stress
Cache the `mapping layers `to enhance read speed - caching data allows us to quickly access locally and improve user interactions as we serve them faster to improve their experiences and engagement! Use the appropriate compression algorithm during transfer and storage and minimize data storage requirements to increase throughput and lower cost to operate

Consider leveraging a specialized hardware (e .g high RAM machines for high-throughput calculations).  This may provide faster execution in specific use cases where data object is massive to ensure performance remains at high level,
## Security Considerations

All communication is SPF-Encrypted to safeguard from potential data compromise as data transmission is important in the context of the project

Input Validation should be strictly enforced across various inputs in both data uploading as REST EndPoint interactions to mitigate risks that might cause vulnerabilities, or injection errors from bad or malicious data
Ensure access controls are implemented for restricting unauthorized access or usage - to limit potential disruption or access violations, it critical

Secrets Management must follow industry practices (for API tokens and kafka connection secrets), using tools that securely encrypt, protect data in a production environments, as this is important. 

For reporting potential security bugs and issues ` contact us immediately` so that our community will resolve quickly - as the project is built and maintained by the citizens for citizen, security of user mapping remains the most top and paramount goal of project! 

## Roadmap

Upcoming feature development for stellar mapper includes: additional projection map capabilities, advanced visualization tooling and more sophisticated statistical mapping models to allow deeper analytics of citizen mapping results - the community can request for this, or even propose new mapping projects
Integration to external scientific repositories to enable broader community collaborations, for increased usages and publication capabilities - so the galaxy mappings and findings become visible globally for everyone!

Our short term goals includes better support with real-time streaming observations for a live-mapped galactic display for a dynamic galactic cartography and a community of scientists

Long term goals involve a self improving platform with an intelligent agent learning and predicting celestial object mapping from existing and future citizen mappings. We plan toward building a dynamic system.

## FAQ

The `common questions about installing our StellarMapper project include issues around dependencies or configurations `. If a kafka is `not available then the application cannot be properly launched as we utilize the platform heavily in building mapping operations, and users need install one before deployment

The API requests fail when no authorization tokens were sent or when authentication settings in API were invalid- check authentication secret keys are set in YAML to be in proper alignment to avoid authorization and validation error messages and issues, and to make API available properly

## Citation
We acknowledge our citizen scientists contributions that enabled all of Stellarmapper to function in its present state! We extend thanks as our galaxy mapping and observation project are only possible because citizen contributions
```bibtex
@software{stellarmapper,
  author = {The StellarMapper Development Team},
  title = {StellarMapper: An Autonomous Celestial Mapping Platform},
  year = {2024},
  url = {https://github.com/stellarmapper}
}
```

## Contact

Should questions or assistance are necessary, we offer various support channel for users: please visit us online, or contact us using support via Github issue for all concerns, feature proposals - we appreciate the engagement, and welcome your feedback! For community collaboration we are using various messaging forums. Join in!