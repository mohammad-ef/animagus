# Task Scheduling System - TSSv5 

## Introduction
TSSv5 is a sophisticated job/ task execution platform designed for automated workflows. It facilitates the scheduling tasks, their dependency management, execution and tracking. The core aim is to minimize resource consumption while guaranteeing job completion based on specified dependencies, and resource constraints. It is built around an architecture that emphasizes modularity and extensibility. 

## Description
TSSv5 solves the problem of manual job coordination across different server locations.  Previously, this involved cumbersome scripting and constant intervention, often leading to failures and delays. This system offers an automated and reliable alternative that reduces human effort and improves job completion reliability. Its central scheduler component efficiently manages task prioritization and resource utilization.

The platform uses a message- queueing architecture.  RabbitMQ is leveraged for reliable task dissemination and acknowledgement. This allows decoupled worker node processes allowing individual node restarts or maintenance while ensuring that all tasks are processed. The core scheduler component uses Redis to efficiently store and manage scheduling data including tasks, dependencies, and worker node information in memory.

Furthermore a web-based UI provides an intuitive interface to monitor task progress with interactive visualizations and reports. The UI can be customized via a configuration file, providing users granular control over its functionality and layout. TSS is capable of running a wide array of tasks through its plugin ecosystem.

Finally, TSS offers robust error handling mechanisms to manage task failures and retry jobs based on pre-defined conditions, preventing job failures and ensuring overall system resilience.  It provides a complete job scheduling and execution solution.

## Installation Instructions

First, install Python 3.8 or greater. This system is primarily built in Python and relies on several key packages which can be installed.  Make sure you have pip installed as a part of your Python installation for package management. Verify Python installation by entering `python3 --version`

Next, clone the repository from GitHub.  This will create a directory with all the project' s code, documentation, and configurations. Use the following command in the terminal to clone the repo:
```bash 
git clone <repository_url>
```

Change your working directory into the newly cloned project directory:
```bash
cd <project_directory>
```

Install the dependencies defined by the `requirements.txt` file using pip :
```bash 
pip3 install -r requirements.txt
```
This command retrieves all the necessary packages from Python Package Index (PyPI) and installs them in your virtual environment. This step will install RabbitMQ and Redis python bindings.

Now you have to install RabbitMQ. On Debian based systems you can install using:
```bash
   sudo apt-get install rabbitmq-server
```
On RHEL based systems use:
    ```bash
    su -c "sudo yum install -y rabbitmq-server"
    ```

Then install Redis:
```bash
sudo apt-get install redis-server
 ```
On RHEL based systems use:
  ```
  sudo yum localinstall --nogpgcheck redis https://yum.postgresql.org/13/redhat/x86_64/repodata/repomd.xml
  ```

Configure Rabbit MQ by starting and then running:
```
sudo systemctl start rabbitmq-server
sudo rabbitmq -username admin -password admin -plug ~/.{setup file}.py
```

Finally ensure that the RabbitMQ service starts upon boot with:

```bash
 sudo systemctl enable rabbitmq-server
```
The same should be done with redis
```bash
sudo systemctl start redis-server
sudo systemctl enable redis-server
```
## Usage Instructions

Once installed, run the scheduler by executing `python3 scheduler.py`. Ensure RabbitMQ and Redis servers are running, since they form the central infrastructure upon which TSS depends. This initializes the central scheduling loop responsible for managing the jobs

Next, start a worker process with the command `python3 worker.py`. A minimum of one worker node must be present in the running architecture and additional instances increase task throughput.. Each worker node will be registered with the scheduler on its starting instance. 

You can also run the command with flags, such as `--worker-id`. This allows to create multiple independent worker nodes which share a task pool with a defined identification
 ```bash
  python3 worker.py --worker-id worker-2
 ```

You can then use a configuration to setup task definition which specifies what jobs are going to be performed in an easy format

Finally view job and execution logs from webui using a configured endpoint
 ```bash
 http://localhost:8000/dashboard
 ```

For complex job execution chains and dependency specifications use advanced job configuration templates. They enable intricate execution patterns like cascading job launches based on completion status of other dependent tasks and resource-based task execution limits for better utilization of resources.

You can use different worker pools which enables the segregation of critical jobs from long execution processes, ensuring higher performance. Each of these pool types are specified through config. The worker id should be unique and assigned based on pool

To execute specific jobs manually using CLI: `python3 execute_job.py <job_id>`

This executes the task specified using task-id, manually bypassing automated queue scheduling process for one-off task. Note it needs scheduler already up

For debugging create dummy workers by using:
`python3 worker.py -d <task name> <number_instances>` to generate tasks
```
 ## Configuration

TSSv5 primarily uses a YAML configuration file ( `config.yaml`) for defining its behaviour. Modify `config.yaml` with the appropriate configurations for job monitoring, task prioritization and scheduling policies.

This YAML file holds the main application configurations including scheduler configurations and task configurations. Modify the RabbitMQ and Redis URL for production environment configurations

Environment variables provide an alternate mechanism for configuration values that can easily overwrite those defined within `config.yaml`. Define variables, and specify `TSS_RABBITMQ_URL` as RabbitMQ URL if the connection settings needs modification

For example to configure task timeouts you will change this:
```yaml
  task_timeout: 3600
```
The scheduler prioritizes tasks through the use of task weights and execution time. Increase task weight value in your YAML, and higher tasks execute.
For more specific configurations regarding UI, such as themes and color palettes refer the comments present in `config.yaml` 

For setting different resource usage types, configure `resource_usage.cores` ,`resource_usage.memory`. 

To enable logging and error capture modify  the  logging levels. You can specify filepaths for different logs as necessary for the application

To configure plugins, define new tasks through `task_plugins`, and update configuration files for plugins as defined per task requirements

## Project Structure

The TSSv5 repository has the following major directories:

*   **`src/`:** This directory contains the core source code for the project, organized into modules. The primary file scheduler.py contains all the main application scheduling functions

*   **`tests/`:** Contains automated unit and integration tests designed to ensure the stability and quality of all code and configurations, and should be updated before committing code

*   **`configs/`:** This directory contains YAML and other configuration files which define the runtime configurations.  These define all task and execution settings
*   **`docs/`:** Project documentation, API descriptions, and installation guidelines, all formatted using the standard MarkDown standards and should reflect code.

*   **`plugins/`:** This folder holds plugins used in extending functionality in different ways like scheduling policies. The `tasks.yaml` file holds definitions and specifications of plugins to use

A brief structure is given:
```
TSSv5/
   src/
     scheduler.py
     worker.py
     ...
   tests/
     test_scheduler.py
     test_worker.py
     ...
   configs/
     config.yaml
   docs/
     README.md
   plugins/
      tasks.yaml
```

## Contributing

We welcome contributions from the open-source community. Feel free to fork the repository and create your own branches. Implement any features as requested and test all functionalities before making commits. Submit all contributions in clear concise messages which explain purpose

When reporting any new issues, first, verify no similar problems has already appear and if they do then contribute.  Submit issues to issue-tracking and be prepared for further discussion, clarifications. Ensure to add clear error and stack traces, as possible
Pull requests need proper descriptions with information on why a contribution makes an application improve

All submitted codes and documentation needs tests implemented for them so the code base is verified and reliable
All submissions require passing lint and style checks

## License

This project is licensed under the MIT License.

This License is provided on an "AS IS" basis, and there are no warranties associated with its functionality and implementation, express or implied, which includes warranties regarding its merchantability or fitness to perform a specified job. This does not restrict your use of this product but provides a permissive open source approach

## Acknowledgments

We would like to acknowledge the invaluable support of the open-source community. Special thanks to the RabbitMQ team for building such an amazing Message queueing solution for task dissemination and acknowledgement

Additionally the core servant and task framework were influenced by a few core principles of Go routines in terms of asynchronous job executions, providing efficient job management across clusters, which we adopted to ensure performance in large setups. Also many thanks to Pytest library developers, who built powerful dynamic frameworks and ensured we had robust tests and documentation standards. 

The core scheduler component architecture and dependency management techniques were greatly impacted from the concepts present in Distributed Systems books which are essential building blocks for modern scalable application designs

## System Architecture

The architecture comprises the main central Scheduling unit that orchestrates Task scheduling using a Message queue system (RabbitMQ). Each scheduler runs on server node to handle jobs efficiently based on the available task queue, worker capacity, configurations in YAML
 
RabbitMQ acts as message queue to store task details including execution parameters as necessary to handle distributed executions and fault tolerence in system architecture and also provides the means for the decoupled nature of execution

Tasks assigned via Queue and Workloads executed concurrently using Worker nodes to improve performance of execution

The Worker processes connect to both Scheduler as necessary through Queue messaging protocol and Redis data- store for maintaining their status in active or pending and available status in Scheduler

Finally User Interfaces and APIs for management purposes interact primarily using a REST type API calls. These provide Monitoring as possible through TLS connections which allows for better system security 

## API Reference

The TSSv5 offers the following endpoints for monitoring:

*   `/task/<task_id>`: GET request returns status information.
*   `/task/<task_id>`: PUT to update. Requires proper access permissions

Workers interact through queue: `TSS_RABBITMQ_URL`. All worker status changes should occur on the queue to be properly monitored on UI dashboards and other components

*    API to register status to central component : /v1/queue
*In case queue not configured use `TSS_WORKER_STATUS_REGISTRY`. Requires proper authorization for access control.  Access via POST with worker status data, to allow scheduler component to maintain accurate view for all workers
  All responses should provide JSON encoded messages and HTTP 401 if authorization issues are reported.
## Testing

We leverage the pytest testing framework in testing our applications to make robust implementations that cover many aspects. Unit Tests verify isolated components functionality. The main integration tests verify interaction with different modules, while ensuring the scheduler and Worker components works. Integration testing includes simulating network and resource dependencies

Use command  `pytest -v tests/` run the testing. You also have test suites available on the Github Actions CI

To setup you should have the following dependencies: 
```
- pytest==7.1.2
- flake8==4.0.0
```
The integration environment for the testing should be able to simulate all necessary external components

## Troubleshooting

If your Scheduler not starts properly double-check `config.yaml` configurations for incorrect settings, as well verify RabbitMQ connection strings are available in `config.yaml`. The RabbitMQ needs configured on server with access for proper connection for Scheduler module
If the task is still not processed verify if workers available to execute jobs in scheduler module using UI

When encountering errors during job scheduling or job queue operations inspect rabbit queues, verify all necessary plugins and modules were loaded

For debugging purposes add logging levels in config files for better understanding in execution flow

To troubleshoot worker not responding to messages in RabbitMQ check the Worker's log file or check Rabbit MQ's health
To ensure proper performance check resource utilization with monitoring UI
Ensure your application has necessary permissions to write files, connect network, run commands
## Performance and Optimization

Optimize task definitions, by breaking jobs that go through lengthy process. Implement proper caching mechanisms for recurring computations to reduce overall load time for task

Leverages concurrent task executions across the cluster of the Worker, as it provides more efficiency for task scheduling by allowing tasks parallelization 

Properly configured and fine tuned resource configurations for each tasks and workers, which allows to maximize system throughput without impacting system health 

For production setups leverage caching techniques on commonly retrieved datasets from task definition for quicker execution, as this allows reduced overhead
Profiling can give insight into performance limitations and bottleneck in execution of code, for optimization opportunities

## Security Considerations

Secure configurations to restrict user roles, to access to configure and view system. Ensure RabbitMQ user does not has full system administrative access to prevent privilege exploitation and malicious access by unauthorized parties. Validate inputs to the Task, to defend the application for malicious input
Enable encryption on RabbitMQ queues for protecting sensitive Task information
Keep software versions and all related library and middleware to mitigate vulnerability issues

For enhanced protection use authentication mechanism, and secure connection using SSL and ensure proper access to configurations, and prevent sensitive keys in repository to secure application environment
Report Security Issues immediately. To provide swift remediation and mitigate impact. Ensure all third party plugins used follow safe development protocols and guidelines 
## Roadmap

- [x] Improved Plugin System
- [x] Support Multi Task execution with dependency chains.
- [ ] Implement Resource Aware task allocation (core + memory usage aware scheduler.)
- [ ] Implement Dynamic Scalability, and allow auto adjustment of workers
- [ ] Integrate to Monitoring platforms along Prometheus. 
## FAQ

How should the `config.yaml` file setup
Ensure configurations matches server setup to reflect proper queue and scheduler access configurations to properly manage system components. Refer comments in configuration

How can workers and scheduler interact properly.  Ensure the worker and task configurations and connection strings in yaml matches properly and all dependencies are met and properly configured on the system, for all connections for workers with central task components.

If tasks fail repeatedly, how will I be alerted on it: Configure the notification service through YAML configurations with alert triggers on failures in the Task executions. Refer config comments
How is the system tested, before deploying new updates: Unit,Integration Testing is used on automated test cases, along continuous Integration on pull-request and code merge.  Run `pytext -v` to ensure testing suite
## Citation

When citing the Task Scheduling System in any publication:
`Task Scheduling System, TSSv5 (2024). Available from: <repository_url>`

Please reference authors in your paper with following BibTex
```BibTeX
@software{tss_v5,
    author = {YourName, Team},
    year = {2024},
    title = {Task Scheduling System v5},
    url = {repository_url},
    version = {5}
}

```
Please provide appropriate credit, if using components in projects 
## Contact

Contact for reporting, and general inquiries can use our dedicated Github Issue.

To get support for this application visit us and contribute
Join our open forum and community at <Link To Your Communication Platform or Slack Channel>
You may also reach our developers for specific queries
