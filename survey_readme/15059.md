# Distributed Key-Value Database - "Krita"

This README serves as a guide for installing, using, contributing to, and understanding the Krita distributed key-value data store. Krita aims to provide high availability, fault tolerance, and scalability for storing persistent data.  It achieves this with a gossip protocol, Raft consensus for updates, and a sharded architecture. Krita is suitable for scenarios requiring high reliability like financial transactions.

## Description ##

Krita is built to be a reliable and scalable key-value storage system.  Data is partitioned across nodes using consistent hashing, ensuring efficient distribution. Each shard replicates data across three nodes for redundancy. Node discovery is achieved using the decentralized gossip protocol.  The database is primarily written in Rust with some bindings to Python for easy use. Krita offers a command- line interface and a REST API for managing your database.

The system utilizes a Raft consensus engine for ensuring all shard replicas are kept synchronized when updates are received.  This guarantees consistency across the distributed storage.  A client library simplifies integration with various applications by offering simple key- value store operations with automatic failover. The architecture is designed for horizontal scalability to meet future needs.

Security is a critical consideration.  All communication is encrypted by TLS. Access controls based on roles are also built in. The data model is simple: a key- value storage. The keys and corresponding values are serialized with Protocol Buffers to minimize space usage. Future versions will include support for other serialization formats.

Krita is designed with operational simplicity in mind.  Automatic node recovery and rebalancing are built in. Detailed metrics are logged for monitoring purposes using Prometheus.  The command- line interface facilitates common tasks like creating, deleting, and querying clusters. This reduces operational overhead.

The project emphasizes modularity and testability. The architecture is broken down into small, independent modules that can be unit tested easily. Integration tests ensure proper coordination among all of the various pieces. The system provides excellent performance due to being written in Rust and employing zero-copy designs in key sections.

## Installation Instructions ##

Before starting, ensure you have Rust and Cargo installed (Rust package manager). You also need to have Git. It helps to have `ripgrep` also, it speeds up testing immensely. We'll assume that `curl` and `wget` are present as well, and Python3 and pip as they are used to build parts of the client libraries. Lastly, install a database for test integration; postgresql is a suitable option.

First, clone the repository from GitHub:

```bash
git clone https://github.com/your-organization/krita-db.git
cd krita-db
```

Next, install the core dependencies, running `cargo build --release`. The `Cargo.toml` file declares project-specific needs like Tokio (for async), Rust's Raft implementation (raft-rs), protobuf compilation toolchain (and a Rust crate for protocol buffer serialization and deserialization).

Once you have completed this you'll want to setup Postgresql if it hasn't been configured, create the user/password for Krita and create the krita DB

Now run this `python3 scripts/generate_client_bindings.py`.  It builds both python and go bindings from Protobuf definition.  Ensure that python version matches the script requirements and that it doesn;t try to compile with Python 2.

You can also install all client bindings, which is required if using Python to manage clusters. Install this: `pip3 install .` in the `python-client` folder to do that. You need this if wanting to do programmatic administration of a Krita DB

If encountering compilation errors with Rust and `protobuf`, ensure you have a supported protobuf compiler version. You can check for protobuf compiler support within Rust's Protobuf integration and install if missing. Check to see what Rust and Protobuf have for versions. It may take tweaking and version upgrades of all components to make them compatible.

To setup environment variables that are used, ensure `KRITA_ADMIN_PASSWORD` has been defined or `kubectl config set-context --current --server-override=http://localhost:8000`.  Ensure the password adheres to policy if enabled (complexity, character constraints, minimum lengths) as the Krita cluster administrator must provide a proper login and be secured against attacks.  For Windows use the system's GUI and the environment variables options there.

On Linux or macOS use `export KRITA_ADMIN_PASSWORD=YourSecretPassword` for local usage but use secure key management practices to store these secrets on deployed nodes

If using Docker, it's important to mount your local directory in your Krita cluster config directory. Otherwise configuration updates might not take place in deployed containers because it uses volumes by default to manage configuration persistence and secrets storage

Finally for Kubernetes ensure `kubeconfig` and your access permissions exist as you are connecting via a remote environment so it simulates a distributed deployment in its cluster

## Usage Instructions ##

Krita is typically controlled via CLI, though the HTTP/REST api provides a great deal of functionality. You first launch at least three cluster nodes. To do so, navigate to the `/cluster` folder, you will have access to launch commands

To start an administrative client to connect, use:

```bash
./admin-client
# Login via `login` with admin and a proper secret.

# To see your node list use: `list-nodes`
# You will want to see at least 3 healthy node connections,
# which should have come up if configured as the above

# to list cluster metadata use `describe-cluster`

```

After launching at least three instances using admin commands from the admin shell. Now you'll have access to CRUD functions using `get-keys`. To put in an example `put "My Key" "Hello World"` then to view this, type `get-key "My Key"`. Note it will show an output as the data could reside on several locations within your private clusters depending node configuration or availability.  You will then see that your values and data will persist through several restarts of all nodes in this distributed system.

For advanced configurations using `shard` and managing the shards you'll need access and permissions that have elevated authority to make cluster alterations that can have a big operational risk. This includes adding or modifying shards that may lead to downtime depending configurations so please be advised! For API requests see documentation at `./docs`

Use `help` frequently.  There's plenty of help within each module. If using the REST APIs and python client library. Refer to API references to find what you may need and how to properly authenticate yourself with your credentials

Krita also comes with example scripts under `/examples` for performing batch operations and cluster migrations using command-line utilities

You will have some limitations with the cluster configuration, for instance a max node limit is 20 to help keep it stable for a distributed system that uses the Gossip protocol and is susceptible to instability in the network

Remember if your node connections become unhealthy it should gracefully re-synchronize but this depends entirely on your setup

## Configuration ##

Krita is primarily configured through a configuration file typically stored at `/etc/krita.yml`. If the path to it cannot be parsed then Krita falls back to reading enviornment variables

Important configurations options are `bind_address` (address where it will be served at on each Node); with `admin_port`, for accessing Admin API; also `listen_port`, where client applications should connect; also you need a secure admin account that will prevent unverified requests, which uses  `admin_username` with a very complicated secret password

There is also options related to replication settings and how much the system prioritizes the consistency versus availability, as it will determine whether it is more willing to provide responses if data hasn;'t yet reached a consistent quorum and this impacts overall performance

Network settings include how it will connect, if UDP protocol or only TCP protocol is acceptable

For testing purpose there may also configurations relating to mocking external database dependencies that can make unit tests quicker, for faster debugging in integration

To change cluster configuration it needs elevated privileges to prevent misconfiguration.

The configuration can dynamically be reloaded if needed.  If it is reloaded it might require some down time, and Krita may experience brief inconsistencies while syncing data among active cluster nodes

If a setting doesn;t match requirements or has syntax mistakes in its formatting configuration will be disregarded as this will ensure it remains functional with fallback values instead

There exists a CLI interface for configuring and setting environment variables directly as an additional way in changing it. It requires authentication before setting any of its cluster settings and can take time, and needs to sync

The admin client offers a CLI for modifying configuration options such as the node's port to bind. To modify, login, `configure`, specify setting `setting` to its proper name with a value of value that is appropriate in format of key=val and `update`. This command has elevated permissions

## Project Structure ##

```
krita-db/
   Cargo.toml              # Project metadata and dependencies
   src/                   # Source code
      core/                # Core data store logic
         consensus/        # Raft implementation
         storage/          # Key-value storage implementation
         gossip/           # Gossip protocol
      cli/                 # Command-line interface.
      api/                 # REST API definitions
      types/            # Types definitions and Protobuf bindings
   tests/                 # Unit and integration tests
      core/
         consensus/
      integration/
   configs/             # Example configuration files
   docs/                   # API Documentation.
   scripts/               # helper and deployment build scripts
   python-client/
     # Python client Library, for managing nodes programatically.
   README.md
```

The `src/core` directory houses the majority of the codebase and core logic for consensus and persistence of data to disks using storage drivers
 The cluster folder will include scripts to build docker container and executables to launch the server
   The testing is structured similarly, with dedicated modules mirroring the structure to provide unit and full testing of modules
 The configuration provides example yaml to set configurations that can change with a running server
The scripts contains utilities which are for managing clusters

## Contributing ##

We welcome contributions to Krita! First, read our `CONTRIBUTING.md` file in the repository to get a complete list of requirements
You should ensure the codebase complies with all Rust and Go formatting styles, which includes `rustfmt` formatting
You should create a fork from your personal git hub profile or repository that will allow us merge into this master and test
Submit your feature as PR, with a proper commit with descriptive and concise comments
Please submit bug fixes through issue reporting
All submitted code requires passing through CI testing with passing tests and coverage reports.
Please ensure all documentation updates, as well
The community has its communication channel at discord and is very responsive. We appreciate help!

## License ##

Krita is licensed under the Apache License 2.0. This license allows you to use, modify, and distribute the software for both commercial and non-commercial purposes. Be sure to include the original copyright notice and the license file in any redistribution.

You are granted to run or fork or create modifications of our codebase as your use but do be wary if your changes impact others, as a pull-request might require additional work, but is welcome nonetheless. This also ensures others will also receive any bug-fix and performance improvements we provide, so be wary to maintain this and share your knowledge if able!

## Acknowledgments ##

We would like to thank the Rust community for its vibrant and supportive ecosystem. The excellent Raft implementation provided by `raft-rs` library forms the base of our Raft Consensus algorithm, making distributed systems development more efficient and easy

We would also thank our test suite contributors who made Krita stable. They provide many hours in reviewing test failures

We acknowledge contributions of Protobuf libraries which allow the serialization between languages and data types, for seamless cross application and communication. This reduces development efforts significantly! Finally and foremost thank contributors from Kubernetes. Krita uses some components in our deployment strategy.

## System Architecture ##

Krita utilizes a distributed architecture consisting of nodes and shards. Nodes act as storage and serve request from application while each shards are groups to ensure redundancy
Nodes connect via gossip protocols and elect cluster members
Each nodes runs consensus engine and keeps track its peers
Data shards use replicated copies and ensures durability, scheduled in 3 replicas per each
Consistent hashing distributes and partitions key-value pair into shard nodes. Each client only access shards

Raft handles all updates in the shard by coordinating between nodes with its consensus algorithms
A Gossip mechanism enables discovery of other node and propagation changes

Client library uses load balancing to select a healthy server for its purpose to serve client needs without failure
This allows to achieve fault-tolerant distributed database that's easily managed in any cloud platform such as Amazon and DigitalOcean

## API Reference ##

* **GET /nodes:**  Returns a list of nodes in the cluster.
    * Request: None
    * Response: JSON array of node details (ID, address, status).
* **PUT /node/{nodeId}:** Create Node, add node,
    * Parameter: id
    * request json payload {address: string; description : String; }
* **POST /shards/add:** add shards. Shard must consist 3 copies of replica nodes that can survive any downtime without any interruption in operations

For details refer `./docs` or `swagger/open_api` to review.

## Testing ##

Run unit tests via cargo tests, this ensures all functions have correct functionality. It will output results for each file in tests. Integration and performance test should have sufficient logging and metrics, with automated reports that will be displayed. You should always examine reports. If running performance tests please monitor memory usages of your server as the test might have unintended behaviors or leaks in your configuration
Use Docker for testing in Kubernetes clusters to make the process simpler
To execute tests `make run` in root of krita repo directory or in docker container
The integration test suite will ensure coordination in various cluster states. This is a must-check when introducing configuration updates and major code change in any cluster. The CI from github ensures passing of integration testing. This can run in containers or on machines that have enough memory

## Troubleshooting ##

* **Node Connectivity:**  If nodes are unable to connect, check network configurations and firewall rules, make sure all the node have a common network
* **Replication Errors:** Verify the consistency and availability, and that nodes have proper communication with peers and consensus, which will be reported by logs

For issues with data corruption check if disk has been compromised, this will lead a node crash

Ensure all configurations is correct, especially regarding admin users. Improper configurations is often a common reason

If using Kubernetes make sure DNS and routing configuration have been applied to ensure inter connectivity of containers, if you encounter problems
## Performance and Optimization ##

Consider using persistent disks to enhance data I/O. Tuning shard sizing based on usage to maximize the efficiency can improve data access

Employ read caches, write buffer caches by setting appropriate settings. This allows read replica nodes for better performance, but at risk with eventual data staleness in data synchronization with Raft algorithm

Concurrency using multiple connections per clients to achieve better parallel data operations can be useful

For high load situations ensure enough node replicas in your configurations to avoid overloading any of the active node in the system
You might also look into additional CPU power in all servers to achieve more data access. Profiling can assist to discover where slowdown is happening to address and mitigate them efficiently

## Security Considerations ##

* All network traffic uses TLS, enabling authentication of connections

Admin access has authentication, to make unauthorized operations difficult
Implement proper validation checks.

Monitor system access events regularly, this may alert suspicious activities, for which immediate responses can protect systems from attacks

Ensure the cluster secrets is rotated to protect your sensitive access credentials against compromises. Use secrets to prevent access
Apply latest patches on a frequent cadence
If logging, sanitize data logs to not include Personally Identifiable Information and protect them

## Roadmap ##

* Support additional replication algorithms such as Paxos and Viewstep, this improves reliability
* Add a geo-distribution for disaster recoveries in a multi datacenter scenario. To make clusters span regions globally
* Integration with popular databases for hybrid setups that provide the best data availability for a range of data access needs

## FAQ ##

* **Q: What are minimum required Node numbers for the clusters**
*A: You will require at least 3 active running instances, otherwise you will not reach a Raft Quorum for consistency in cluster state operations

* **Q: I see some latency while getting key. what to look for ?**
 * A: It means the data has gone over the network which will cause additional latency to reach client from cluster

* **Q: How can to improve overall speed when inserting or getting key values ?**
   *A: Tune shard to increase number to achieve higher availability, this may also lead faster look ups if the node load decreases significantly
   . It might have unintended behaviors with data staleness
. You may try enabling caches

## Citation ##

We are not yet available as formal research but imagine we can, it would likely look something along those lines:

`@misc{krita-db,
author = {Your Organization},
title = {Krita: A Distributed Key-Value Database},
year = {2024},
url = {https://github.com/your-organization/krita-db}
}`

You should acknowledge the Raft protocol for achieving the consistent operations of our consensus, the Gossip Protocols to manage the network nodes, Protocol Buffers that allow seamless serialization

## Contact ##

For any inquiries or issues reach out to KritaDB at contact@your-domain.com for support related matters
If you have feature proposals feel free to create PR, as our project thrives upon collaborative community efforts

Community forum for discussing with other user are also on our GitHub page in a Discord chat
We appreciate contributions that help our community, please provide bug fixes as needed