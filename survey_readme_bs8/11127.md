# Automated Log Processor (ALPEX - ALP v2)

This is ALP v2, also referred to as Automated Log Processor, built primarily with the aim of streamlining system and security log analysis across heterogeneous environments using automated rule application. It is built primarily around parsing log data into a structured output format suitable for further automated decision making and anomaly detection workflows.  The system offers configurable log file input, rule processing, and a detailed reporting mechanism.  A focus in ALP v. is extensibly.

ALP v2 addresses the common challenges faced by system administrators in dealing with the ever- increasing volumes of log data generated by different applications and services and varying output formats. Manual log analysis consumes significant time and increases the risk of missed security and operational issues. This framework aims to significantly alleviate that burden and automate log data handling processes and anomaly recognition workflows. We are using a rule based system to parse logs.

The system is structured around several key components: a log intake module that ingests logs from files or streams; a processing engine containing a configurable suite of log parsing rules; an anomaly detection module for flagging potentially suspicious patterns;  a reporting module that summarizes events and generates alert notifications; and, a configurable rule engine that allows developers to extend and modify parsing rules without needing to alter the core system. Finally, it is modular.

ALP v2 is primarily targeted at DevOps teams, system architects managing large-scale IT deployments, or cybersecurity personnel tasked with analyzing potential security threats. It is especially useful in cloud environments where logs are often scattered across multiple services and require consistent, standardized interpretation. We envision it integrating with security information and event management (SIEM) solutions to provide automated enrichment with parsing data.

The core architecture of ALP v2 is designed around modularity and extensible parsing rules. Log intake is decoupled from processing, enabling seamless data integration across diverse sources. The rule-based engine provides a structured means for parsing and analyzing log messages, enabling flexible and precise extraction of relevant information. The modular and extensible design allows for future expansions and integrations with different systems. It can be extended with a REST API.

## Installation Instructions

First, you need to ensure Python 3.9 or higher is installed on your system and that pip is available as a package manager. It is highly recommended to use a Python virtual environment to avoid interfering with other packages.

To create the virtual env using the python3 interpreter:
  ```shell
  mkdir alpex && cd alpex
  python3 -m venv .venv
  ```
Activate the environment with the command specific to your operating system. Windows users will use:  `.venv\Scripts\activate`, whilst Linux and macOS use: ` source .venv/bin/activate`.

Then, clone the ALP v2 repository from its GitHub repository:
 ```shell
   git clone https://github.com/your-alp-project/alpex.git #Replace with the actual repository
    cd alpex
 ```
Install the project's required dependencies using pip. Ensure your virtual env is activated.
```bash
     pip install -r requirements.txt
```

Linux users may require `sudo apt- get update` before installing Python if Python is not already on the system.

On macOS, if you encounter any issues with `pip`, try to update ` pip`:  using `  pip install --upgrade pip`.  Sometimes this resolves dependency conflicts.  

For Windows users utilizing Anaconda, the environment creation is done by conda, using the `conda env create` command. Ensure to activate it.

It is crucial after installing the necessary dependencies that all the libraries were installed correctly. Verify with `pip list`. Check if all of the items in `requirements.txt` exist in the list.

## Usage Instructions

To run ALP v with a basic configuration, start by creating a sample input log file ( `input.log`). Add some test log lines, such as `2023-10 -27 10:00:00 INFO: System boot complete `and `2023-10-27 10:01:00 WARNING: Disk space low`.

Now, run ALP v2 using the command:  `python main.py --log_file input.log   --rule_set rules.yaml  --output output.json`. This command instructs the program to process the  `input.log` using the  `rules.yaml` rule set, and output the extracted data into a `output.json` file.

For an advanced use case, define complex parsing rules within `rules.yaml` targeting specific log formats. The rules can be tailored to extract unique identifiers, timestamps, error levels, and other contextual information for detailed reporting. This enables advanced anomaly detection and customized reports. This can be extended to a REST API.

The system will produce an output file in JSON format. Each parsed log line will be a dictionary with keys corresponding to the elements extracted by the rules. This enables easy integration with other data analysis tools.

You can adjust the output formats by modifying the rules.yaml config file, as described in the configuration.

## Configuration

ALP v2 is highly configurable through a combination of command-line arguments, environment variables, and YAML configuration files. The core of the configuration is contained in `rules.yaml`. The command line flags will over ride config in  `rules.yaml`.

The rule file (rules.yaml) is defined using the YAML file extension format. In that config file each parser contains: input regexes to capture relevant values; name, and output fields to return for parsed records. For complex expressions regular expressions (regex) should be tested before being committed.

You can define multiple environments to support varying operational contexts by configuring the appropriate values within environment specific variables within environment specific rules files in separate `.yaml` directories (such as "dev", "test", "prod"). You should not skip setting environment values as incorrect configuration may break parsing.

Furthermore, several system configuration options are supported by env vars like `LOG_DIR`, `ANOMALY_THRESHOLD`, controlling aspects such as data ingestion source location and triggering alerts thresholds and logging level of operations, respectively. The default value in a `.yaml` configuration overrides environment settings and is therefore the final decision factor.

For debugging the rules and configurations the `-d` or `--debug` command can be set and used for detailed logging of internal operation, to better understand any misbehaviors within system modules or data flows, especially when parsing custom and unknown formats of source.  It can expose valuable diagnostic insights, and is helpful in the tuning stages.

Custom rules must conform to syntax standards described and outlined, within a YAML specification document in the root repository directory, for the ALP engine parser to be able to interpret and utilize. Incorrect formatting is one of the commonest configuration issues found in use.

To specify multiple config rules in sequence use an extended rule file with a comma seperated configuration in rules.yaml file with entry rules. Each entry is evaluated, if successful parsed data can continue the flow down stream or it can break depending on the rule value, which affects subsequent execution stages, as specified with a `proceed`.

## Project Structure

The project repository uses a directory-based architecture:

-   `alpex/`: This is the root directory of the project containing setup and config instructions.
-   `src/`:  Contains the source code files, mainly python scripts responsible for core operations. `main.py` represents entry point application and contains options handling module logic
-   `tests/`: Includes a range of integration examples, as well as testing framework to validate core logic, and test edge cases in various input data sets.. `pytest` can execute tests, which can easily identify regressions introduced.
-   `configs/`: Holds YAML rule configuration file (`rules.yaml`) as described previously. It can host other configs such as database or system-dependent configs for future versions
-   `data/`: Example files used for demonstrations or testing such as test input `input.log`. Can host other example configuration for demonstrations, like custom parsing configs to use
-   `docs/`: The `README` is also stored inside this root and provides project introduction and guidance, along with usage details in markdown files..  It may host diagrams describing architecture or usage patterns for better documentation,
- `requirements.txt`: Specifies external libraries required.


## Contributing

We welcome contributions to ALP v2 to enhance functionality, correct bugs, and expand its versatility.

1.  **Issue Reporting:** Please submit feature requests or bug reports as a new issue within the GitHub repository, providing concise and descriptive steps with example log files that reproduce the problems to facilitate faster triage.
2.  **Pull Requests:** When contributing code improvements submit through GitHub's pull request feature and align with standard coding and naming. Follow a similar structure of the current codebase to improve code understanding in the future
3.  **Coding Standards:** The source is PEP 8 style with comprehensive test files included and is enforced in a CI/CD setup for continuous code health and to guarantee compatibility for all team users, including third-party integrations
4.  **Testing Expectations:** Submit comprehensive and descriptive tests, as part of each pull request with a detailed and clear purpose for the change that it introduces

## License

ALP v2 is released under the **MIT License**.

This License grants the freedom to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to which the Software is furnished to do so, subject to the included conditions of the licensing documentation which are to acknowledge proper source.



## Acknowledgments

We want to give a sincere gratitude to all developers who helped shape, refine, test, document, debug ALP. A massive amount of effort from many different collaborators has resulted in ALP being what it is currently

This tool builds on the foundations of successful parsing tools that have been used to build modern monitoring, and observability frameworks

ALP leverages concepts of modular software design that can provide scalability across a multitude of diverse architectures that require parsing, monitoring and observability frameworks



## System Architecture

The overarching structure revolves around three central phases - ingestion, extraction processing, reporting output

Log intake modules receive raw messages via streams and file system and provide buffering before being parsed and extracted into organized objects with specific metadata

Parsers and regular expressions applied translate unstructured strings, identifying relevant information and structuring extracted components within a unified object. It also handles error scenarios where input fails, allowing recovery

Lastly Reporting is outputted, and it provides configurable output formatting with alerts. This can output data for other monitoring frameworks, like Splunk and Elasticsearch

Dataflows move through the three central processes as raw log lines become parsed and transformed information that are integrated in a monitoring dashboard. The parsing stage is designed so rulesets could be dynamically reconfigured at runtime with new or updated regex to provide a robust data stream that will always dynamically parse log formats as the system is being developed

## API Reference

At this current phase there isn;t much of an external facing API for ALP as it focuses entirely in the internal parsing process, it does contain the basic CLI functionality. However a plan has been laid for adding it to an API, using Fastapi in Python as a base layer for a simple interface, that exposes a REST end point and can process incoming raw data streams while returning a processed list of parsed messages that are in an JSON structured

This will have the basic functions like `post /api/parseLogData`, which is an input of a stream as an argument for an input stream of data

`GET /api/config?rulesetName`: retrieves an example yaml file to configure. 

Currently these will have very rudimentary functions but are a basis for the API in a near phase

## Testing

We heavily emphasize testing. To launch our existing set of automated test, simply go inside `src` folder within `main.py`, which uses the framework `pytest`. It requires Python. It will check if your implementation aligns and behaves properly

``` bash
  python -m pytest tests/test_parsers.py tests/test_log.py
```

For running integration testing the framework is set for automatic running, as new parsers/ configs can be added into this section without impacting the main system and is a safety and verification step for continuous development practices and processes in development



## Troubleshooting

One frequent difficulty stems from inaccurate regular expressions or rulesets and are the top most cause issues with the current setup

Another difficulty comes about with inconsistent and unvalidated source data format or parsing rules and can result in incomplete data being reported or even failures. It helps debugging when the data is consistent or known for debugging issues in rule creation



## Performance and Optimization

Performance bottlenecks can originate from the complexity or quantity in log entries

We encourage pre- processing the input and filtering before passing data for efficient execution by using aggregation and sampling techniques, and limiting data to essential components to be analyzed



## Security Considerations

It requires extreme sensitivity, when storing secrets or authentication tokens for the log ingestion module; we advocate encrypting them using dedicated tools such as KeyVault. We are using environment configuration and secure config practices, and this will allow secure configuration to happen

Regular input sanitization and proper escaping can minimize code-based risks, which will allow safe code implementation. Input validation should take advantage



## Roadmap

Our future plans entail implementing the full RESTful API that can parse raw stream of input. A goal also includes the support integration for multiple cloud sources as Salesforce , Google AD or Azure for unified data ingestion in centralized dashboards, as well, more flexible data format for reporting



## FAQ (Frequently Asked Questions)

What is best way configure a specific environment variable. Environment variables need be set outside application and passed into application when run, for flexibility across multiple configurations for environments



Where do logs come from; Can this parse multiple log inputs at same time Yes! The framework handles file input as streaming sources to provide multiple parsing at once to maximize throughput. The logs should come either local or through a stream such as network connection, depending configuration

## Citation

If the use or integration for a specific use of this product is needed cite this product, using the reference information listed
```text
 Automated Log Processor v2 [software]  https://github.com/your-alp-project/alpex.git  (accessed May 8, 2024)

```
Or BibTeX:
```text
 @misc{alpexv2,
  author = {Your Author(s) if contributed,  ALP Contributors if using public},
  title = {Automated Log Processor v2},
  year = {2024},
  note = {https://github.com/your-alp-project/alpex.git},
  url = {https://github.com/your-alp-project/alpex.git}
}
```

## Contact

Please reach out with suggestions. Consider opening new feature or bugs, asking on our GitHub repository at your project URL and can contribute

For further contact use a dedicated Slack channels at your project. We will review your request as quick as time allows!